{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Questions\n"
      ],
      "metadata": {
        "id": "_E3KbRvcCckg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Can we use Bagging for regression problems?**\n",
        "\n",
        "--> Yes, Bagging (Bootstrap Aggregating) can be used for regression problems. In regression, Bagging involves training multiple regression models (like Decision Trees) on different random subsets of the training data (with replacement). The final prediction is obtained by averaging the predictions of all the individual models. This reduces variance and helps in building more robust models.\n",
        "\n",
        "**Q2. What is the difference between multiple model training and single model training?**\n",
        "\n",
        "--> Single model training involves training one algorithm on the complete dataset. In contrast, multiple model training (as in ensemble learning) combines the predictions from several models. Multiple models can reduce overfitting, increase accuracy, and generalize better on unseen data. It takes advantage of the strengths of different models, while a single model may suffer from bias or variance issues.\n",
        "\n",
        "**Q3. Explain the concept of feature randomness in Random Forest.**\n",
        "\n",
        "--> In a Random Forest, feature randomness means that at each decision tree split, a random subset of features is considered instead of all features. This helps in making the trees more diverse and less correlated with each other. This randomness reduces overfitting and leads to better generalization.\n",
        "\n",
        "**Q4. What is OOB (Out-of-Bag) Score?**\n",
        "\n",
        "--> OOB score is an internal validation method used in Bagging and Random Forests. When training each tree, a bootstrap sample (random sample with replacement) is used. The data not included in this sample is called Out-of-Bag data. The OOB score is calculated by testing the model on these OOB samples, providing a reliable performance estimate without using a separate validation set.\n",
        "\n",
        "**Q5. How can you measure the importance of features in a Random Forest model?**\n",
        "\n",
        "--> Feature importance in Random Forest is calculated based on how much each feature decreases the impurity (like Gini index or entropy) across all trees in the forest. A feature that frequently results in large impurity reductions is considered more important. This can be visualized using feature importance plots.\n",
        "\n",
        "**Q6. Explain the working principle of a Bagging Classifier.**\n",
        "\n",
        "--> A Bagging Classifier works by training multiple base classifiers (like Decision Trees) on random subsets of the training data with replacement (bootstrap samples). Each model gives its prediction, and the final output is determined by majority voting (for classification). This helps in reducing variance and overfitting, especially for high-variance models.\n",
        "\n",
        "**Q7. How do you evaluate a Bagging Classifier’s performance?**\n",
        "\n",
        "--> You can evaluate a Bagging Classifier using classification metrics such as accuracy, precision, recall, F1-score, and ROC-AUC. Additionally, the OOB score can be used as an internal validation metric. Cross-validation is also commonly used to assess performance on unseen data.\n",
        "\n",
        "**Q8. How does a Bagging Regressor work?**\n",
        "\n",
        "--> A Bagging Regressor works similarly to the classifier but is used for continuous output. It trains multiple regression models (e.g., Decision Tree Regressors) on different bootstrap samples and combines their outputs by averaging the predictions. This approach reduces variance and increases robustness.\n",
        "\n",
        "**Q9. What is the main advantage of ensemble techniques?**\n",
        "\n",
        "--> The main advantage of ensemble techniques is improved model performance. They combine multiple models to reduce overfitting, increase accuracy, and improve generalization. Ensembles can often outperform individual models by reducing errors due to bias or variance.\n",
        "\n",
        "**Q10. What is the main challenge of ensemble methods?**\n",
        "\n",
        "--> The main challenge of ensemble methods is increased complexity. They require more computational resources and training time. Also, understanding and interpreting ensemble models (like Random Forests or Boosting) can be harder compared to simpler models like a single Decision Tree.\n",
        "\n",
        "**Q11. Explain the key idea behind ensemble techniques.**\n",
        "\n",
        "--> The key idea of ensemble learning is to combine multiple base models to produce a stronger and more accurate overall model. By aggregating the decisions from diverse models, ensembles can balance out errors made by individual models, leading to better performance and generalization.\n",
        "\n",
        "**Q12. What is a Random Forest Classifier?**\n",
        "\n",
        "--> A Random Forest Classifier is an ensemble learning method that builds multiple Decision Trees using random subsets of the data and features. Each tree gives a prediction, and the final prediction is decided by majority vote. It is robust to overfitting and performs well on both classification and regression tasks.\n",
        "\n",
        "**Q13. What are the main types of ensemble techniques?**\n",
        "\n",
        "--> The three main types of ensemble techniques are:\n",
        "\n",
        "Bagging (e.g., Random Forest) – Reduces variance.\n",
        "\n",
        "Boosting (e.g., AdaBoost, XGBoost) – Reduces bias.\n",
        "\n",
        "Stacking – Combines multiple models using a meta-model.\n",
        "\n",
        "**Q14. What is ensemble learning in machine learning?**\n",
        "\n",
        "--> Ensemble learning is a technique where multiple models (often called \"weak learners\") are combined to create a \"strong learner.\" The idea is that a group of weak models can work together to produce more accurate and reliable predictions than any single model.\n",
        "\n",
        "**Q15. When should we avoid using ensemble methods?**\n",
        "\n",
        "--> You should avoid using ensemble methods when:\n",
        "\n",
        "The dataset is very small and simple models perform well.\n",
        "\n",
        "You need a highly interpretable model.\n",
        "\n",
        "Computational resources are limited.\n",
        "\n",
        "The gain in accuracy is not worth the added complexity.\n",
        "\n",
        "**Q16. How does Bagging help in reducing overfitting?**\n",
        "\n",
        "--> Bagging reduces overfitting by training each model on a different random subset of data, making the models less sensitive to noise. By averaging the predictions (regression) or voting (classification), it smooths out individual fluctuations and errors, resulting in a more generalizable model.\n",
        "\n",
        "**Q17. Why is Random Forest better than a single Decision Tree?**\n",
        "\n",
        "--> Random Forest is better than a single Decision Tree because:\n",
        "\n",
        "It reduces overfitting.\n",
        "\n",
        "It increases accuracy by averaging over many trees.\n",
        "\n",
        "It handles missing values and unbalanced data better.\n",
        "\n",
        "It is more robust and stable due to ensemble averaging.\n",
        "\n",
        "**Q18. What is the role of bootstrap sampling in Bagging?**\n",
        "\n",
        "--> Bootstrap sampling is the process of creating multiple random subsets (with replacement) from the original dataset. Each model in Bagging is trained on a different bootstrap sample, which introduces diversity among the models and helps reduce variance and overfitting.\n",
        "\n",
        "**Q19. What are some real-world applications of ensemble techniques?**\n",
        "\n",
        "--> Real-world applications of ensemble methods include:\n",
        "\n",
        "Fraud detection\n",
        "\n",
        "Medical diagnosis (e.g., cancer detection)\n",
        "\n",
        "Customer churn prediction\n",
        "\n",
        "Stock price prediction\n",
        "\n",
        "Recommender systems\n",
        "\n",
        "Image and speech recognition\n",
        "\n",
        "**Q20. What is the difference between Bagging and Boosting?**\n",
        "\n",
        "--> Bagging and Boosting are both ensemble methods that combine multiple models to improve prediction accuracy, but they differ in how they train and combine these models. Bagging, or Bootstrap Aggregating, trains multiple models independently on different subsets of the data, and then averages their predictions. Boosting, on the other hand, trains models sequentially, with each subsequent model focusing on the errors made by the previous models"
      ],
      "metadata": {
        "id": "FAM06jEGCgws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "GS2i2Hp0FCpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6fBvexACcJB",
        "outputId": "66cfc32a-f410-4ca2-8000-16736c5b4efc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSS6I_GOFwWB",
        "outputId": "5c291101-cf9b-4411-aad9-fb05b9d9f9f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3256.961797752809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "importances = clf.feature_importances_\n",
        "for name, score in zip(data.feature_names, importances):\n",
        "    print(f\"{name}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQYCPzPTGLKe",
        "outputId": "1ce32507-ac98-432f-ce91-532958dd95f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean radius: 0.0487\n",
            "mean texture: 0.0136\n",
            "mean perimeter: 0.0533\n",
            "mean area: 0.0476\n",
            "mean smoothness: 0.0073\n",
            "mean compactness: 0.0139\n",
            "mean concavity: 0.0680\n",
            "mean concave points: 0.1062\n",
            "mean symmetry: 0.0038\n",
            "mean fractal dimension: 0.0039\n",
            "radius error: 0.0201\n",
            "texture error: 0.0047\n",
            "perimeter error: 0.0113\n",
            "area error: 0.0224\n",
            "smoothness error: 0.0043\n",
            "compactness error: 0.0053\n",
            "concavity error: 0.0094\n",
            "concave points error: 0.0035\n",
            "symmetry error: 0.0040\n",
            "fractal dimension error: 0.0053\n",
            "worst radius: 0.0780\n",
            "worst texture: 0.0217\n",
            "worst perimeter: 0.0671\n",
            "worst area: 0.1539\n",
            "worst smoothness: 0.0106\n",
            "worst compactness: 0.0203\n",
            "worst concavity: 0.0318\n",
            "worst concave points: 0.1447\n",
            "worst symmetry: 0.0101\n",
            "worst fractal dimension: 0.0052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor()\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "dt_pred = dt.predict(X_test)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_pred))\n",
        "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzi4bl0sGVA9",
        "outputId": "f3049d35-8d71-48c0-9269-74800a7cc0bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 0.07017543859649122\n",
            "Random Forest MSE: 0.03276140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"OOB Score:\", clf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrHvs9oQGZo2",
        "outputId": "da899aef-5656-4b91-c65f-b294d21b4047"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9560439560439561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "bag_svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=42)\n",
        "bag_svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = bag_svm.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y08PCbrmGd03",
        "outputId": "2c85797f-9d0d-4626-cd04-02cbce5d108f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "\n",
        "for n in [10, 50, 100, 200]:\n",
        "    model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc = model.score(X_test, y_test)\n",
        "    print(f\"{n} Trees - Accuracy: {acc:.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV-DtSgPGi9M",
        "outputId": "8ffda9be-660a-482f-e1b0-9910fdb8c2c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Trees - Accuracy: 0.9561\n",
            "50 Trees - Accuracy: 0.9649\n",
            "100 Trees - Accuracy: 0.9649\n",
            "200 Trees - Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "log_reg = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=2000)  # Scaled + higher max_iter\n",
        ")\n",
        "\n",
        "model = BaggingClassifier(\n",
        "    estimator=log_reg,\n",
        "    n_estimators=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"AUC Score:\", roc_auc_score(y_test, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4zrOdiXGon5",
        "outputId": "d93a3e29-f47d-49af-95fa-9a34b07adff3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score: 0.9963969865705864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores\n",
        "\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "importances = reg.feature_importances_\n",
        "for i, val in enumerate(importances):\n",
        "    print(f\"Feature {i}: Importance = {val:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GtIfDk9GtGR",
        "outputId": "954b78e3-8666-4e37-e37a-069be722a441"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: Importance = 0.0014\n",
            "Feature 1: Importance = 0.0211\n",
            "Feature 2: Importance = 0.0025\n",
            "Feature 3: Importance = 0.0051\n",
            "Feature 4: Importance = 0.0067\n",
            "Feature 5: Importance = 0.0008\n",
            "Feature 6: Importance = 0.0047\n",
            "Feature 7: Importance = 0.2028\n",
            "Feature 8: Importance = 0.0027\n",
            "Feature 9: Importance = 0.0021\n",
            "Feature 10: Importance = 0.0037\n",
            "Feature 11: Importance = 0.0038\n",
            "Feature 12: Importance = 0.0039\n",
            "Feature 13: Importance = 0.0102\n",
            "Feature 14: Importance = 0.0035\n",
            "Feature 15: Importance = 0.0017\n",
            "Feature 16: Importance = 0.0066\n",
            "Feature 17: Importance = 0.0033\n",
            "Feature 18: Importance = 0.0035\n",
            "Feature 19: Importance = 0.0053\n",
            "Feature 20: Importance = 0.1035\n",
            "Feature 21: Importance = 0.0255\n",
            "Feature 22: Importance = 0.1589\n",
            "Feature 23: Importance = 0.1182\n",
            "Feature 24: Importance = 0.0085\n",
            "Feature 25: Importance = 0.0018\n",
            "Feature 26: Importance = 0.0118\n",
            "Feature 27: Importance = 0.2699\n",
            "Feature 28: Importance = 0.0042\n",
            "Feature 29: Importance = 0.0024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "bag.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Bagging Accuracy:\", bag.score(X_test, y_test))\n",
        "print(\"Random Forest Accuracy:\", rf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRi_-JRlG_a_",
        "outputId": "4ca430f7-6464-4325-a8b0-576e7181d925"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Accuracy: 0.956140350877193\n",
            "Random Forest Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBuRy2u5HFPn",
        "outputId": "8703cf2c-0fcb-4644-b7f1-621f492f7329"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
            "Best Accuracy: 0.9582026257697223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
        "\n",
        "for n in [10, 50, 100]:\n",
        "    reg = BaggingRegressor(n_estimators=n, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    pred = reg.predict(X_test)\n",
        "    print(f\"{n} Estimators - MSE: {mean_squared_error(y_test, pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBcF7kGgHfMS",
        "outputId": "5a60a3ef-6d37-4757-f66f-8ca7aa7aa74a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Estimators - MSE: 0.0375\n",
            "50 Estimators - MSE: 0.0336\n",
            "100 Estimators - MSE: 0.0320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "misclassified = X_test[y_pred != y_test]\n",
        "print(\"Number of misclassified samples:\", len(misclassified))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIrdUO8HHjuc",
        "outputId": "cf8535a8-3f6f-484d-ca95-9247a9426f7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified samples: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "bag = BaggingClassifier(estimator=dt, n_estimators=10, random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "bag.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", dt.score(X_test, y_test))\n",
        "print(\"Bagging Accuracy:\", bag.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCFyAGKFHn0A",
        "outputId": "47d5084f-cf53-4022-b1be-7ddf8b883dd9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9473684210526315\n",
            "Bagging Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Train a Random Forest Classifier and visualize the confusion matrix\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rr9sugAhHrcw",
        "outputId": "51c722f2-f056-42c3-9202-46ed32f1c3fd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7979dc44eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base models with scaling where needed\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True))),\n",
        "    ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000)))\n",
        "]\n",
        "\n",
        "# Final meta-learner (default is LogisticRegression, you can also scale it if needed)\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=2000))\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "print(\"Stacking Accuracy:\", stack.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAPSOge7HxWo",
        "outputId": "8058494c-c5ca-463c-d051-4330fe2ae2c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "importances = clf.feature_importances_\n",
        "top_indices = np.argsort(importances)[-5:][::-1]\n",
        "\n",
        "for i in top_indices:\n",
        "    print(f\"Feature {i} - Importance: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDdPSmgxH01l",
        "outputId": "76bf847c-cfe2-4a71-dfd5-5ebb9253bf71"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 23 - Importance: 0.1539\n",
            "Feature 27 - Importance: 0.1447\n",
            "Feature 7 - Importance: 0.1062\n",
            "Feature 20 - Importance: 0.0780\n",
            "Feature 6 - Importance: 0.0680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "bag.fit(X_train, y_train)\n",
        "y_pred = bag.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5pnpTgEH8Es",
        "outputId": "2aea5f24-931b-4e27-a192-c19db3687c65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        43\n",
            "           1       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "\n",
        "for depth in [3, 5, 10, None]:\n",
        "    model = RandomForestClassifier(max_depth=depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    acc = model.score(X_test, y_test)\n",
        "    print(f\"Max Depth = {depth} -> Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CfvtRh7H_VH",
        "outputId": "3f3507c1-f464-4ee1-80bf-6993cd69038e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth = 3 -> Accuracy: 0.9649\n",
            "Max Depth = 5 -> Accuracy: 0.9649\n",
            "Max Depth = 10 -> Accuracy: 0.9649\n",
            "Max Depth = None -> Accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "for base in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
        "    name = type(base).__name__\n",
        "    bag = BaggingRegressor(estimator=base, n_estimators=10, random_state=42)\n",
        "    bag.fit(X_train, y_train)\n",
        "    pred = bag.predict(X_test)\n",
        "    print(f\"{name} - MSE: {mean_squared_error(y_test, pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x6G1YRHIEFx",
        "outputId": "8472d4f4-5e86-4734-e511-8871c711cab0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeRegressor - MSE: 0.0375\n",
            "KNeighborsRegressor - MSE: 0.0294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbkRUDrLIH2M",
        "outputId": "4792a7f9-21c4-4d5a-fd63-cb4b240008a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9952505732066819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "bag = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
        "scores = cross_val_score(bag, X, y, cv=5)\n",
        "\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqcT5TwjINFi",
        "outputId": "95590159-25b0-4301-c538-d47fc3e1ba69"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.92982456 0.93859649 0.97368421 0.93859649 0.97345133]\n",
            "Mean Accuracy: 0.9508306163639186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curve\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, probs)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "6S8BY_XvIR3p",
        "outputId": "9fb2b45e-b985-44a1-dcf4-8a0934ee13be"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7979d98f5510>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier()),\n",
        "    ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000)))\n",
        "]\n",
        "\n",
        "# Meta-learner with scaling too\n",
        "final_estimator = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
        "\n",
        "stack = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "print(\"Stacking Accuracy:\", stack.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_p40KXWIWrT",
        "outputId": "b873e060-b812-474e-c3b0-4dba8a56a42e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "\n",
        "for bootstrap in [True, False]:\n",
        "    reg = BaggingRegressor(n_estimators=10, bootstrap=bootstrap, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    pred = reg.predict(X_test)\n",
        "    print(f\"Bootstrap={bootstrap} - MSE: {mean_squared_error(y_test, pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWnmyjE0IZ9J",
        "outputId": "a6618fc2-cd91-4ea1-bf33-dcc2df773ff7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap=True - MSE: 0.0375\n",
            "Bootstrap=False - MSE: 0.0583\n"
          ]
        }
      ]
    }
  ]
}